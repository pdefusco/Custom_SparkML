{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fc0a6f-485c-415e-bc56-4a02ed255a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56596152-cdd3-4bad-80b7-2bbf94322501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    input_col = Param(Params._dummy(), \"input_col\", \"input column name.\", typeConverter=TypeConverters.toString)\n",
    "    output_col = Param(Params._dummy(), \"output_col\", \"output column name.\", typeConverter=TypeConverters.toString)\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "        self._setDefault(input_col=None, output_col=None)\n",
    "        kwargs = self._input_kwargs\n",
    "        self.set_params(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def set_params(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "\n",
    "    def get_input_col(self):\n",
    "        return self.getOrDefault(self.input_col)\n",
    "\n",
    "    def get_output_col(self):\n",
    "        return self.getOrDefault(self.output_col)\n",
    "\n",
    "    def _transform(self, df: DataFrame):\n",
    "        input_col = self.get_input_col()\n",
    "        output_col = self.get_output_col()\n",
    "        # The custom action: concatenate the integer form of the doubles from the Vector\n",
    "        transform_udf = F.udf(lambda x: '/'.join([str(int(y)) for y in x]), StringType())\n",
    "        return df.withColumn(output_col, transform_udf(input_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08227f3-a59d-4b29-a4b7-aa429d2e0dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to pauldefusco\n",
      "Hive Session ID = 6623bf11-46e2-47c4-8be0-79c98cb376fd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|         01_car_data|\n",
      "|           01_car_dw|\n",
      "|             airline|\n",
      "|          airline_dw|\n",
      "|            airlines|\n",
      "|        airlines_csv|\n",
      "|       airlines_csv1|\n",
      "|   airlines_csv_vish|\n",
      "|    airlines_iceberg|\n",
      "|   airlines_iceberg1|\n",
      "|airlines_iceberg_...|\n",
      "|          airquality|\n",
      "|          atlas_demo|\n",
      "|            bankdemo|\n",
      "|              bhagan|\n",
      "|             cdedemo|\n",
      "|        cdp_overview|\n",
      "|        cgsifacebook|\n",
      "|               claim|\n",
      "|           clev_bank|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cml.data_v1 as cmldata\n",
    "\n",
    "CONNECTION_NAME = \"go01-aw-dl\"\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark = conn.get_spark_session()\n",
    "\n",
    "# Sample usage to run query through spark\n",
    "EXAMPLE_SQL_QUERY = \"show databases\"\n",
    "spark.sql(EXAMPLE_SQL_QUERY).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b86fab2-1dc1-49fd-9637-61b3bea6bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ElementwiseProduct\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df61209b-45c5-4df5-a6a0-9fd57f1e577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(Vectors.dense([2.0, 1.0, 3.0]),), (Vectors.dense([0.4, 0.9, 7.0]),)], [\"numbers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77ef144-01ee-43f6-a323-8a9e25e54325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------+\n",
      "|      numbers|       product|results|\n",
      "+-------------+--------------+-------+\n",
      "|[2.0,1.0,3.0]|[4.0,3.0,15.0]| 4/3/15|\n",
      "|[0.4,0.9,7.0]|[0.8,2.7,35.0]| 0/2/35|\n",
      "+-------------+--------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "elementwise_product = ElementwiseProduct(scalingVec=Vectors.dense([2.0, 3.0, 5.0]), inputCol=\"numbers\", outputCol=\"product\")\n",
    "custom_transformer = CustomTransformer(input_col=\"product\", output_col=\"results\")\n",
    "pipeline = Pipeline(stages=[elementwise_product, custom_transformer])\n",
    "model = pipeline.fit(df)\n",
    "results = model.transform(df)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbe399-57ef-4f33-97d8-7dbfdad1aa68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
